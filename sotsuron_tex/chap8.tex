% !TEX root = thesis.tex
\chapter{おわりに}
\section{研究の成果}
この研究では、深層学習をウェブ工学の問題に適用するにあたって、その特徴である高い精度を落とすことなく、出来るだけ簡便に応用するための方法論とノウハウを調査した。Pylearn2に実装されている、Maxout Networkを用いることで、論文に書かれている精度をほぼ再現することが出来た。また、GPUを使うと大幅な高速化が見込めることがわかった。

\section{今後の課題}
画像分類タスクにおいて有効な方法が、ウェブ工学のデータでも必ず有効かどうかは、未知数な部分がある。例えば、畳み込みネットワークは、2次元の画像データに対しては非常に高い効果を挙げるが、そのまま文章データに応用することは出来ない。Pylearn2で言えば、Datasetクラスを作るだけで識別がうまくいくのか、文章専用のModelを構成する必要があるのか、確かめていく必要がある。\par
また、精度を上げるためには、どのようにハイパーパラメータを調整すれば良いのか、あるいは精度を多少犠牲にしてでも、比較的短い実行時間で良い結果を得たい時、どのような調整を施せばよいのかは、まだわかっておらず、今後の大きな課題の一つである。\par
現在の深層学習が比較的得意とする画像データ処理について、単純な認識タスクで大量の訓練データが用意されている条件ならば、畳み込みレイヤーによる特徴抽出が非常に良い性能を示す。しかし、問題設定を少し変えて、「シンボルを1つだけ見せて、他のシンボルの中から同じものを選ばせる(one-shot classification)」「シンボルを1つだけ見せて、同じシンボルを機械と人間に書かせ、どちらが上手く出来るか競う(one-shot generation)」といった、データ数が非常に少ない条件下では、まだ人間が手間をかけて作った素性を使った方が性能が高いことがある\cite{lake2013one-shot}。画像をただ認識するだけでなく、良い素性の作り方を少ないデータから学習できるようになれば、繰り返し回数を減らし学習時間を短縮することにもつながり、応用の幅が広がると思われる。\par
深層学習を試す上で、大きなネックとなるのが、CUDAを用いたGPU専用のソースコードの存在である。GPUを搭載していなかったり、使えるメモリが少ない状況下でも、深層学習のコードを効率良く動かすことが出来れば、深層学習の利便性はますます増加するだろう。\par
現在の深層学習では、画像のフィルタで何が学習されているのかを、部分的に可視化することはできる。しかし、文書解析において、どのような表現を学習したのかを、人間に理解できる形でみることは難しい。言い換えれば、学習によって、分類器がどこに注目するようになったのか、文構造や、感情、文体などに対応するニューロンが存在しているのか、といった情報が、人間に理解できる形になっていない。この部分をどうやって可視化して、人間に理解できる状態にするか、そこからどのような知見を得られるのか、あるいはそもそも人間には理解出来る知識として取り出せるのかどうか、といったことを調べることにより、表現学習としての深層学習の側面を、さらに活かすことができると思われる。例えば、深層学習にょって学習された、データの着目点や抽象化のポイントを、人間が真似することによって、人間の方が機械から知識を習得し、さらに発展させることも考えられる。
