% !TEX root = thesis.tex
\chapter{考察と提言}
この章では、5章と6章の結果に対する考察を行うと共に、考察結果を踏まえ、Deep Learningの実問題における効率的な応用方法について、提言を行う。

\section{5章の実験に関する考察}
\subsection{全体の結果のまとめ}
5章の実験では、ソーシャルメディアのユーザ属性推定において、プロフィール画像からの推定手法を模索した。実験の結果、SDA、SVM共に、Facebookのユーザプロフィールにて1人分の顔画像が使われているという条件ならば、ある程度ユーザの性別を識別できることがわかった。\par
\subsection{SDAにて良い精度が出なかった理由の考察}
識別自体にはある程度成功したとはいえ、本来画像認識や多段階の推論で効果を発揮すると思われるDeep Learningを使用したにも関わらず、従来から用いられている単純なSVMによる精度を上回ることが出来なかった。この理由はわかっていないが、考えられることとして、まず実験で用意したデータ数の不足や偏りが考えられる。例えば、Deep Learning全般が大きな成果を挙げているMNISTのデータセットには、全体で70000のデータが用意されている。また、CIFAR10でも60000件のデータが利用可能である。比べて、今回用意できたデータは3746件のみであり、男性と女性のデータ数には1.3倍ほどの開きがあった。このデータの不足と偏りが、学習傾向に歪みを与えてしまった可能性がある。\par
また、隠れレイヤー数、レイヤー内ユニット数など、学習モデルを形成する様々なハイパーパラメータの調整を行うことで、学習制度を向上させることができる可能性がある。SVMの場合、grid searchと呼ばれる方法によってパラメータを調整している。しかし、この方法はハイパーパラメータが増加するにつれて指数関数的にかかる時間が増大してしまう。パラメータが1〜3個程度で済むSVMでは有効な方法だが、パラメータ数が非常に多いSDAや他のDeep Learningの方法では、現実的ではない。ハイパーパラメータを自動的に調整する方法が必要である。
\subsection{今後の発展について}
今回の実験では、まず最も確実性の高いところから検証するということで、単体の顔プロフィール画像のみを識別のターゲットとした。しかし、キャラクターやブランドロゴなどの非実写アイコンや、人間の横顔、複数人が映った画像からでもユーザ属性が推定できれば、より応用での確実性が増す。性別だけでなく、ユーザの好みや交友関係の傾向も推測できれば、これも貴重な情報となる。人間の行動や思考は、テキストだけでなく、ファッションや交友関係など非言語的な特徴にも顕れる。こういった情報も学習できるようになれば、システムの利用価値が高くなっていくと思われる。\par
Facebookは、本人画像の使用率が比較的高いコミュニティとして一般に知られている。有名人の画像利用問題が考えられるにも関わらず、ある程度精度良く識別が出来たのも、対象がFacebookだったからということは考えられる。Facebookだけでなく、Twitterなど、本人画像以外がプロフィール画像に使われやすいソーシャルメディアでも、ユーザ属性が推定出来れば、応用が容易になると考えられる。

\section{6章の実験に関する考察}
\subsection{全体のまとめ}
pylearn2におけるMaxout Networkは、元論文に記されている精度こそ再現できなかったものの、MNISTの分類タスクにおいてState of the Artに近い精度を実現することが出来た。Maxout Networkを利用することで、少なくとも画像認識のタスクにおいて精度を向上させることが出来ると考えられる。\par
\subsection{分類誤差が大きくなってしまう原因の考察}
今回の実験では、MNISTの1次元版、2次元版共に、元の論文やpylearn2ソースコードの付属テキストに書いてあった分類誤差よりも、大きい誤差しか再現できなかった。また、この誤差が大きくなってしまう問題は、複数回の実験を行っても、解決しなかった。\par
分類精度が悪くなってしまった理由として、当初、図\ref{c7_maxout_cause}に挙げた3つの原因が考えられた。しかし、複数回実行しても全く同じ結果が出たため、乱数のシードを変更しない限り、内部的には全く同じ演算が成されていると考えられる。よって、「重みのランダム初期化」、つまり「ニューラルネットワークの接続の重みがランダムに決まっており、たまたま分類に不利な重みからスタートしたため、元の論文よりも悪い結果が出てしまった」という仮説は否定される。残る可能性は、「ソースコードのバージョン」と「ハードウェア構成の違い」であるが、GPUを始めとする各パーツの性能は、元論文の実験時に使われたものよりも、今回の実験で使ったものの方が高いため、「ハードウェアの性能」に原因を求めるのも難しい。残る可能性は「ソースコードのバージョン」である。これは、pylearn2が依存しているライブラリの、numpyやscipy、Theanoまたpylearn2自体などがアップデートされたことにより、内部的に細かい計算方法が変化し、分類誤差の再現性が下がってしまった、という仮説である。\par
実験の再現性については、Maxout Networkの元実験を行ったメンバーも、
\begin{quote}
All of pylearn2's dependencies (theano / scipy / numpy / etc.) make reproducibility
very difficult. As such, we are not currently going to make any effort to ensure that
all results are widely reproducible on a variety of platforms. Instead, we will
record the platform on which they were verified to be correct.
\end{quote}
と記している(pylearn2のソースコード\footnote{\url{pylearn2/scripts/papers/maxout/notes}}より引用)。彼らの認識でも、まずソースコードやライブラリのバージョンが重要であり、またハードウェアの性能も影響すると考えられていることが読み取れる。\\
\begin{figure}[tbp]
 \begin{center}
  \includegraphics[width=80mm]{img/c7/maxout_error_cause}
 \end{center}
 \caption{Maxout NetworkによるMNIST分類実験で、誤差が論文より大きくなった原因}
 \label{c7_maxout_cause}
\end{figure}
\subsection{CIFAR10の実行時間が非常に長くなってしまう問題について}
今回の実験では、MaxoutによるCIFAR10の分類を、実行時間があまりにも長くかかるため、断念してしまった。実行時間をどうすれば短縮できるのか、特にハードウェアを変えず、分類精度も犠牲にしないで、出来れば長くとも1日程度の実行時間で収束させるための方法がないか、検討を重ねる必要がある。その後の実験により、モデルの学習中に統計情報を収集させる部分で時間がかかってしまっている可能性があるとわかっている。精度を変えずに時間短縮をするための、大きなポイントの1つとして、追求を続ける必要がある。


\section{深層学習の利用法に関する提言}
Maxout Networkが良い精度を実現できたこと、改造のしやすさ、GPU利用の簡便さなどを考え合わせると、現時点では、pylearn2を通してDeep Learningを利用するのが良いと考えられる。
Deep Learningを利用する上で、最も求められる高い識別性能は、Maxout Networkを利用することで担保できる。Maxout Networkは、画像に対してはConvolutional Layerと併用することにより、ほぼstate of the artと遜色ない精度を実現することができる。また、対象が画像ではなく、1次元の広がりしかもたないデータの場合、Convolutional Layerを使うことは出来ないが、現時点では最も高い識別精度を出すことが出来る。この識別性能は、画像データだけでなく、他のデータを扱う際にも有用だと思われる。また、任意の連続関数を近似できるため、かつての単層パーセプトロンのように、理論的に学習できない関数が出現するということもない。Deep Learningに識別精度を求める場合、Maxout Networkを使うのが最も有効な方法の1つである。\par
Maxoutの既存実装としては、論文の著者自らが提供しているライブラリの、pylearn2を使うのが最も確実である。この実装を使えば、論文にて述べられている分類精度にかなり近い精度を、実際に実現することができる。厳密には、論文の分類精度よりも、若干性能は劣化してしまうが、著者が実験を行ったときのハードウェアと、ソースコードのバージョンを揃えずとも、かなり近い精度を再現できることも、また事実であり、実用上はあまり問題にならないと考える。\par
Deep Learningの大きなネックの1つとして、その長い実行時間が挙げられる。この問題は、実行時にGPUを利用することによってかなり緩和できるが、CUDAを用いた専用のプログラムを書く必要があり、難易度が比較して高くなってしまう。この難点は、計算アルゴリズムを書くときに、数値計算/数式処理ライブラリであるTheanoを利用することで、かなり楽になる。Theanoで書いたプログラムは、GPU上でも利用でき、CPUのみのマシンでも、実行速度は下がるが問題なく動かすことができる。また、科学技術計算プログラムの記述においてメジャーなpythonで書かれており、C言語のプログラムに比べて記述が容易であるにも関わらず、事前にCUDAのコードを生成\&コンパイルする仕組みにより、C言語でCUDAのコードを全て記述した場合と代わらない速度で動かすことができる。\par
pylearn2はTheanoの機能をフルに活用して記述されており、またSpaceクラスや画像による可視化など、Theanoに不足している部分にもフォローがされている。pylearn2を使えば、Theanoの恩恵をそのまま受けることができる。この点でも、pylearn2は望ましいと考えられる。\par
pylearn2は、規模の比較的大きいライブラリではあるが、ソースコードは再利用性を強く意識して記述されており、モジュール化が明確である。libsvmのような、テキストファイルにデータを書くだけで利用できるような仕組みは残念ながら用意されていないが、例えば入力データを差し替えるだけならば、Datasetクラスの内容を把握して書くだけで済む。また、アルゴリズムにて使われているハイパーパラメータを調整するだけなら、ソースコードを書く必要すらなく、設定用のyamlファイルを変更するだけで調整を済ませることができる。この「利用する部分だけ把握すれば良い」という性質は、モジュール化の大きな利点であり、そのままpylearn2の大きな利点でもある。