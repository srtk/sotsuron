% !TEX root = thesis.tex
\chapter{関連研究}
\section{Web工学と機械学習}
この節では、Web工学における課題をいくつか例示し、それらの課題を解決するために、機械学習がどのように用いられてきたかを概観する。
\subsection{Recommendation System}
主にWebショッピングを含むサイトや、Web広告の配信において求められる技術である。Webサイトを閲覧しているユーザに対し、そのユーザが購入したいと商品を予測して、Web上の広告などの形で推薦する。適切な広告を表示することにより、ユーザの購買行動を促進することが出来る。
Recommendation Systemの研究は、1992年のTapestryシステムに始まる\cite{goldberg1992using}。また、少なくとも90年代の終わりには、Amazon.com, CDNOW, eBay, Levis, GroupLensなど、様々なサイトにてRecommendation Systemは利用されていた\cite{resnick1997recommender}。
Recommendation Systemを実現するための、機械学習のテクニックとしては、大きく2種類が挙げられる\cite{koren2009matrix}。1つは、Content Filteringと呼ばれ、ユーザや商品の属性や購買傾向を学習することことで、推薦を行う。もう1つはCollaboraitive Filteringと呼ばれており、ユーザや商品の属性を扱う代わりに、購入や評価といった、ユーザの過去の行動を基にして、推薦を行う。
\subsection{Link Prediction}
グラフにおいて、現在のノード間接続から未来の接続を予測する
ソーシャルグラフの予測、タンパク質の反応予測(PPI)に有効である
[加筆]
\subsection{Sentiment Analysis}
ユーザの感想データを手に入れられるようになってきた\\
事実だけでなく、他の人がどのような感情を抱いているのかを分析したい\\
opinion miningという語も広義には似た内容を指している\\
2001-2003に研究が出始めた\\
common neighbors\\
Jaccard係数 SVDによる次元削減\\
Stanfordによるデモに言及

\subsection{Learning to Rank}
多様なランキング素因を組み合わせて、ランキング関数を作成\\
→どの組み合わせが有効か、機械学習する\\
\section{機械学習で利用される、代表的な分類器}
機械学習のプロセスは、「入力データを、数学的モデルで使える素性に変換する」「素性を数学的モデルに入力して、出力値を得る」「出力を見ながら、モデルを修正する」という行程に大きく分けられる。データの分類問題を機械学習で解く場合、モデルによる出力値が分類結果に対応するよう、モデルを学習させることになる。この場合、モデルのことを分類器とも呼ぶ。\\
機械学習において、素性への変換部分は、データの種類に大きく依存する。一方、分類器に用いる数学的モデルと、モデルの改修法、つまり学習法は、汎用的に使うことができる。あるいは、画像や音声、文章といったデータの多様性を、素性という一般的な数値に落とし込むことで吸収して、汎用的分類モデルでも学習できるようにしている。\\
Deep Learning、あるいはDeep Neural Network(多層ニューラルネットワーク)は、汎用的分類モデルの一種である。ここでは、Deep Learningの他にどのような分類器が存在するのか、代表的なものを述べる。
%\subsection{線形識別モデル}

%\subsection{ロジスティック回帰}

\subsection{Support Vector Machine}
Support Vector Macine(SVM)は、データを2つのクラスに分類する能力を持っている。\par
カーネルマジックとマージン最大化により、優れた精度を出している。SVMは、画像認識などに既に実用化されている。[加筆]\\
SVMは、広くその信頼性が認められたモデルの1つであり、ライブラリの利用方法も確立している。例えば、libsvm\footnote{\url{http://www.csie.ntu.edu.tw/~cjlin/libsvm/}}やliblinear\footnote{\url{http://www.csie.ntu.edu.tw/~cjlin/liblinear/}}は使用が容易なライブラリとしてよく知られている。これらのライブラリを使うと、簡単な所定の方式に沿って入力データファイルを用意し、CUI上で2,3回の操作をするだけで、SVMによる分類を行わせることができる。このとき、利用者が自分でプログラムを書く必要は全くない。プログラムを書かないで済むと、手軽に利用することができ、またバグを起こす危険性が非常に少なく安全に使うことができる。\par
Deep Learningについては、このようなライブラリはまだ存在していないため、Deep Learningの代表的なアルゴリズムについて、プログラム無しで利用できるようなライブラリの整備が望まれる。
\subsection{ニューラルネットワーク}
ニューラルネットワークは、人間の脳の構造を模倣した数学的モデルである。人間の脳は、ニューロンと呼ばれる神経細胞が大量に接続されて出来ている。ニューロンが電気信号を伝達することで、様々な脳の働きが行われている、と考えられている。\par
\subsubsection{ニューラルネットワークの伝達方式}
以後、機械学習におけるニューラルネットワークのニューロンを、慣例に従ってユニットと呼ぶことにする。ニューラルネットワークでは、ユニットからユニットへの接続が網目のように広がっている。ユニットは入出力の機能を持つ。これは、生体におけるニューロンが、他のニューロンから化学的な刺激を受け取り、受け取った刺激に応じて自らも他のニューロンを刺激する構造を真似ている。ユニットは入力を受け取ると、活性化関数(activation function)を使って入力値を変換し、接続先のユニットへ出力する。このとき、ユニットからユニットへの結線に、重み(weight)と呼ばれる係数を付与して、出力を変化させることが普通である。これは、生体のニューロン同士の接続が、脳の学習につれて強固になり、刺激がより伝わりやすくなっていくことに対応させている。
\subsubsection{パーセプトロン}
パーセプトロンとは、ニューラルネットワークの一種である。入力データを受け取る役割のユニット群と、出力を引き受けるユニット群が明確に分離されていて、つながりが入力から出力への一方向に限られているものを指す。始めに提唱されたのは、入力層と出力層の2層から成る、単層パーセプトロンと呼ばれるモデルだった。このモデルは、後に線形関数しか近似できないことがわかり、いったん下火になった\cite{minsky1988perceptrons:}。例えば、単層パーセプトロンでは、XOR関数を学習させることが出来なかった\par
しかし、隠れ層を追加し、バックプロパゲーションという方法で学習を行わせることにより、非線形関数を近似可能となることがわかり、再び有用な識別モデルとして脚光を浴びた。\cite{rumelhart1986learning}\par
バックプロパゲーションの弱点として、活性化関数として主に用いられるシグモイド関数の性質があった。バックプロパゲーションに用いられてきたシグモイド関数は、入力と重みの積が大きくなるにつれて、誤差への反応が小さくなってしまい、学習の進行が遅くなるという問題を抱えていた。この問題は、特に隠れ層を2層以上にしたとき顕著になった。多層ニューラルネットワークを学習させる方法が課題となっていた。

%\subsection{Restricted Boltzman Machine}
