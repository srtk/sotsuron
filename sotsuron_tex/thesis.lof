\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces 機械学習の一般的プロセス}}{2}
\contentsline {figure}{\numberline {1.2}{\ignorespaces ディープラーニングで画像を認識する流れ}}{3}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Deep Learningによる、顔の構成要素の学習結果}}{4}
\contentsline {figure}{\numberline {1.4}{\ignorespaces 猫を認識するニューロン (教師無しYoutubeビデオより学習された。)}}{5}
\contentsline {figure}{\numberline {1.5}{\ignorespaces 上 : 入力画像の中で、ニューロンが最も強く反応した48枚　下 : 計算上、最もニューロンが強く反応する画像}}{5}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Link Predictionの問題設定}}{9}
\contentsline {figure}{\numberline {2.2}{\ignorespaces Stanford大が製作した、Deep LearningによるSentiment Analysisの例}}{10}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Support Vector Machineのマージン最大化}}{12}
\contentsline {figure}{\numberline {2.4}{\ignorespaces 直線にて分類できない場合}}{12}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Imagenetの画像とラベル構造の例}}{16}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Supervisionによる画像分類の結果の例}}{16}
\contentsline {figure}{\numberline {3.3}{\ignorespaces DeViSEの学習方法}}{17}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Deep Belief Networkの構造と、学習過程}}{18}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Restriceted Boltzman Machineのネットワーク構造}}{19}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Autoencoderの構造図}}{21}
\contentsline {figure}{\numberline {3.7}{\ignorespaces 画像に対するDenoising Autoencoder}}{22}
\contentsline {figure}{\numberline {3.8}{\ignorespaces Denoising Autoencoderの模式図}}{22}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Stacked Denoising Autoencoderにおける学習の進行}}{23}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Convolutional Netの仕組み}}{23}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Convolutional Netとfeature map}}{25}
\contentsline {figure}{\numberline {3.12}{\ignorespaces Maxpoolingと、Maxpooling Layerの作用}}{25}
\contentsline {figure}{\numberline {3.13}{\ignorespaces max pooling layerを取り入れたConvolutional Network}}{25}
\contentsline {figure}{\numberline {3.14}{\ignorespaces DropoutによるTIMITデータベースの識別結果}}{26}
\contentsline {figure}{\numberline {3.15}{\ignorespaces DropConnectの模式図}}{27}
\contentsline {figure}{\numberline {3.16}{\ignorespaces Heavisideの階段関数}}{28}
\contentsline {figure}{\numberline {3.17}{\ignorespaces Sigmoid関数}}{28}
\contentsline {figure}{\numberline {3.18}{\ignorespaces Rectifier関数}}{29}
\contentsline {figure}{\numberline {3.19}{\ignorespaces Maxout Networkの構造図}}{30}
\contentsline {figure}{\numberline {3.20}{\ignorespaces Maxout Unitが凸関数を近似する様子(1次元の場合)}}{30}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces 既存コードの利用における、完全オリジナルコードの作成に対する利点}}{32}
\contentsline {figure}{\numberline {4.2}{\ignorespaces 既存ソースコード利用のリスクと、対処方法}}{32}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Theanoの動作過程}}{35}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Pylearn2の実験計画例}}{37}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces MNISTデータの例}}{40}
\contentsline {figure}{\numberline {5.2}{\ignorespaces CIFAR10データの例}}{42}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Maxout NetworkによるMNIST分類実験で、誤差が論文より大きくなった原因}}{46}
\addvspace {10\p@ }
