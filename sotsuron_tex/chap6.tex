% !TEX root = thesis.tex
\chapter{考察と提言}
この章では、5章の結果に対する考察を行うと共に、これまでの章の内容を踏まえ、深層学習の実問題における効率的な応用方法について、提言を行う。

\section{5章の実験に対する考察}
この節では、5章で行った様々な組み合わせのベンチマーク実験の結果について、考察を述べる。特に、4章で挙げた「分類誤差の再現の問題」が解消できているかどうかを確かめる。

\subsection{Maxout Networkの分類性能の再現結果}
表\ref{c6_maxout_mnist_result}は、5章でも載せたMaxout NetworkによるMNISTの分類結果と、Maxout Networkの元論文にて記されていた分類誤差を比較したものである。順序不変と畳み込み有りの双方のタスクにて、元の論文より僅かに分類誤差が増加してしまっていることがわかる。しかし、畳み込み有りの方では、依然として表\ref{c5_mnist_rank}にて示した最先端の結果にかなり近い精度を保っている。また、順序不変タスクでも、実用上大きな問題となるような性能劣化は起きていない。\par
まとめれば、Pylearn2におけるMaxout Networkは、元論文に記された精度の厳密な再現こそ出来なかったものの、順序不変と畳み込み可能の2種類のMNISTの分類タスクにおいて、共に最先端に近い精度を再現することが出来ており、Maxout Networkの使用によって「分類誤差の再現の問題」はほとんど解決出来ると言える。特に、順序不変タスクにてMaxout Networkが良い精度を出したことから、他の1次元ベクトルデータを扱うデータに対しても、Maxout Networkを用いることで、分類精度を向上させることが出来ると考えられる。
\begin{table}[tdp]
\caption{Maxout NetworkによるMNIST分類再現の結果}
\centering
\begin{tabular}{|c|c|c|c|c|}\hline
手法 & データセット & 元論文の誤差 & 実験誤差 & 増加分\\ \hline
Maxout + 畳み込み & MNIST & 0.45\% & 0.51\% & +0.06\% \\ \hline
Maxout Network & MNIST(PI) & 0.94\% & 1.16\% & +0.12\% \\ \hline
\end{tabular}
\label{c6_maxout_mnist_result}
\end{table}

\subsection{分類誤差が大きくなってしまう原因の考察}
今回の実験では、MNISTの1次元版、2次元版共に、元の論文やPylearn2ソースコードの付属テキストに書いてあった分類誤差よりも、大きい誤差しか再現できなかった。また、この誤差が大きくなってしまう問題は、複数回の実験を行っても、解決しなかった。\par
分類精度が悪くなってしまった理由として、当初、図\ref{c6_maxout_cause}に挙げた3つの原因が考えられた。しかし、複数回実行しても全く同じ結果が出たため、乱数のシードを変更しない限り、内部的には全く同じ演算が成されていると考えられる。よって、「重みのランダム初期化」、つまり「ニューラルネットワークの接続の重みがランダムに決まっており、たまたま分類に不利な重みからスタートしたため、元の論文よりも悪い結果が出てしまった」という仮説は否定される。残る可能性は、「ソースコードのバージョン」と「ハードウェア構成の違い」であるが、GPUを始めとする各パーツの性能は、元論文の実験時に使われたものよりも、今回の実験で使ったものの方が高いため、「ハードウェアの性能」に原因を求めるのも難しい。残る可能性は「ソースコードのバージョン」である。これは、Pylearn2が依存しているライブラリの、NumpyやScipy、TheanoまたPylearn2自体などがアップデートされたことにより、内部的に細かい計算方法が変化し、分類誤差の再現性が下がってしまった、という仮説である。\par
実験の再現性については、Maxout Networkの元実験を行った方も、
\begin{quote}
All of Pylearn2's dependencies (Theano / Scipy / Numpy / etc.) make reproducibility
very difficult. As such, we are not currently going to make any effort to ensure that
all results are widely reproducible on a variety of platforms. Instead, we will
record the platform on which they were verified to be correct.
\end{quote}
と記している(Pylearn2のソースコード\footnote{\url{Pylearn2/scripts/papers/maxout/notes}}より引用)。彼らの認識でも、まずソースコードやライブラリのバージョンが重要であり、またハードウェアの性能も影響すると考えられていることが読み取れる。\par
\begin{figure}[tbp]
 \begin{center}
  \includegraphics[width=100mm]{img/c6/maxout_error_cause}
 \end{center}
 \caption{Maxout NetworkによるMNIST分類実験で、誤差が論文より大きくなった原因}
 \label{c6_maxout_cause}
\end{figure}
\subsection{CIFAR10の実行時間が非常に長くなってしまう問題について}
今回の実験では、MaxoutによるCIFAR10の分類を、実行時間があまりにも長くかかるため、断念してしまった。実行時間をどうすれば短縮できるのか、特にハードウェアを変えず、分類精度も犠牲にしないで、出来れば長くとも1日程度の実行時間で収束させるための方法がないか、検討を重ねる必要がある。その後の実験により、モデルの学習中に統計情報を収集させる部分で時間がかかってしまっている可能性があるとわかったため、精度を変えずに時間短縮をするための、大きなポイントの1つとして、追求を続ける必要がある。\par
ハードウェアを買わず、既存のハードウェアをやりくりして性能を上げる方法として、複数台マシンによる分散処理が挙げられる。論文の中には、数日規模の計算を行っているものもあり、分散処理を行わせる価値は高い。例えば、\cite{krizhevsky2012imagenet}では、複数台のGPUマシンを用いて畳み込みネットワークの学習を行わせている。このとき、GPU間で計算結果を通信する部分がボトルネックになると予想されるが、この研究ではニューロンをGPUごとに分担させ、一部のレイヤーでのみ同期通信を行うことで、GPU間通信の回数を抑えて対処している。分散処理の弱点は通信自体にかかる時間だけではなく、同期部分において最も遅いマシンがボトルネックになってしまうという点もある。例えばGPUマシンとCPUマシンが混交している場合、CPUマシンの性能と同じ速度しか出なくなってしまうことが挙げられるが、この問題は、ある程度の回数まで同期の無視を認めることで解決できる\cite{ho2013more}。

\subsection{Maxout Network以外のモデルについて}
今回の実験では、Maxoutの他にも、Deep Learning TutorialのSDA、CNN、DBN、Pylearn2のSDA、CNN、Deep Learning TutorialのCNNを基にしたDReDNetを用いた。しかし、どれもMaxoutネットワークの分類精度を上回ることは無かった。\par
この結果に対する理由として、まず分類モデルの差異は大きな要因であると考えられる。特に、DReDNetについては、元論文の実験ソースコードが示されていないまま実装を行ったため、モデルに大きな差異が生まれてしまっている危険性がある。\par
ただ、もう1つ大きな原因として、今回用いたSDA、CNN、DBNの実装では、どれも分類精度を最大にするためのハイパーパラメータがあらかじめ与えられていなかったという点が考えられる。Maxout Networkの実装では、論文の分類誤差を再現させるため、あらかじめ全てのハイパーパラメータ及び、学習率の変化方法などが、詳細にチューニングされた状態で提供されていた。この違いも、分類誤差の違いに大きく結びついていると考えられる。

\subsection{GPUの利用による実行時間短縮について}
今回の実験では、GPUを搭載したphysalisサーバと、搭載していないartemisサーバという、2つの異なるマシンを用いた。2つのマシンにて、Deep Learning Tutorialの3モデルを動かした結果を比較した(表\ref{c6_gpu_result})。2つのマシンはGPUの有無以外にも性能差があるため、一概に比較はできないものの、GPUを搭載しているphysalisマシンの方は、SDAで14.5倍、CNNで27.35倍もの速度上昇を果たしていることがわかる。この2つのモデルについては、GPUを利用することで、4章で挙げた「実行時間の問題」をかなり大きく緩和することが出来ると言える。なお、DBNでは2.05倍の速度上昇に留まっており、深層学習モデルの中でも、GPUの恩恵を受けやすいモデルと、影響が少ないモデルが存在することもわかる。これについては実装による差異も大きいと予想できるので、更なる調査が必要である。\par
なお、DBNとCNNではphysalisマシンの方が誤差が少し小さく、SDAではartemisマシンの方が分類誤差が減少している。これについては、artemisマシンとphysalisマシンでは、実験を行った時期が少しずれているため、numpyなど内部ライブラリのバージョンが異なっている可能性があると考えられる。

\begin{table}[tdp]
\caption{2種類のマシンによるDeep Learning Tutorial+CIFAR10の分類誤差および実行時間}
\centering
\begin{tabular}{|c|c|c|c|c|}\hline
マシン名 & GPU & DBNの結果 & SDAの結果 & CNNの結果\\ \hline
physalis & 有り & 50.90\% ,115分 & 58.64\% ,92分  & 34.76\% ,28分  \\ \hline
artemis & 無し & 51.01\% ,236分 & 56.94\% , 1335分 & 35.18\% ,766分 \\ \hline
\end{tabular}
\label{c6_gpu_result}
\end{table}


\section{深層学習の利用法に関する提言}
現時点で「分類精度の再現の問題」を解決するためには、Maxout NetworkのPylearn2による実装を使って深層学習を利用するのが有効であると考えられる。また、Pylearn2はモジュール化や整備されたドキュメントによる利用・改造のしやすさ、Theanoの利用によるGPU利用の簡便さなどの性質も併せ持っており、「実装難易度の問題」「実行時間の問題」への対策としても非常に有効である。\par
深層学習を利用する上で、最も求められる高い識別性能は、Maxout NetworkのPylearn2実装を利用することで再現出来ることがわかった。厳密には、論文の分類精度よりも、若干性能は劣化してしまうが、著者が実験を行ったときのハードウェアと、ソースコードのバージョンを揃えずとも、かなり近い精度を再現できることも、また事実であり、実用上はあまり問題にならないと考える。Maxout Networkは、画像に対しては畳み込みレイヤーと併用することにより、ほぼ最先端と遜色ない精度を実現することができる。また、対象が画像ではなく、1次元の広がりしかもたないデータの場合、畳み込みレイヤーを使うことは出来ないが、やはり最先端の分類精度を出すことが出来る。この識別性能は、画像データだけでなく、他のデータを扱う際にも有用である。また、任意の連続関数を近似できるため、かつての単層パーセプトロンに対するXOR関数のように、理論的に学習できない関数が出現するということもない。深層学習に識別精度を求める場合、Maxout Networkを使うのが最も有効な方法の1つであるとして良いだろう。\par
深層学習の大きなネックの1つとして、「実行時間の問題」が存在する。この問題は、実行時にGPUを利用することによってかなり緩和できるが、CUDAを用いた専用のプログラムを書く必要があり、難易度が比較して高くなってしまう。この難点は、計算アルゴリズムを書くときに、数値計算/数式処理ライブラリであるTheanoを利用することで、かなり楽になる。Theanoで書いたプログラムは、GPU上でも利用でき、CPUのみのマシンでも、実行速度は下がるが問題なく動かすことができる。また、科学技術計算プログラムの記述においてメジャーなnumpyをベースに書かれており、C言語のプログラムに比べて記述が容易である。しかも、事前にCUDAのコードを生成\&コンパイルする仕組みにより、C言語でCUDAのコードを全て記述した場合と代わらない速度で動かすことができる。\par
Pylearn2はTheanoの機能をフルに活用して記述されており、またSpaceクラスや画像による可視化など、Theanoに不足している部分にもフォローがされている。Pylearn2を使えば、Theanoの恩恵をそのまま受けることができる。「実装難易度の問題」の観点でも、Pylearn2は望ましいと考えられる。\par
Pylearn2は、規模の比較的大きいライブラリではあるが、ソースコードは再利用性を強く意識して記述されており、モジュール化が明確である。LIBSVMのような、テキストファイルにデータを書くだけで利用できるような仕組みは残念ながら用意されていないが、例えば入力データを差し替えるだけならば、Datasetクラスの内容を把握して書くだけで済む。また、アルゴリズムにて使われているハイパーパラメータを調整するだけなら、ソースコードを書く必要すらなく、設定用のyamlファイルを変更するだけで調整を済ませることができる。この「利用する部分だけ把握すれば良い」という性質は、モジュール化の大きな利点であり、そのままPylearn2の大きな利点でもある。\par
また、Pylearn2はgithub上にて開発が活発に進められており、開発者によるメーリングリストなどのコミュニティも盛んである。開発コミュニティが大きいことは、長く使われるライブラリにとって非常に有利と言える。例えば、github上で開発されているプロジェクトでは、所定のルールに従えば誰でもソースコードの改良を提案することが出来る。Pylearn2の開発は、元々の開発者であるLISA.研究室だけでなく、このような多数の改良提案を採用することで、加速度的な進行が期待できる。