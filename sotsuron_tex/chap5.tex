% !TEX root = thesis.tex
\chapter{深層学習の実装例とその検証}
この章では、4章で挙げた問題点の対策を検証するため、いくつかの深層学習用の実装を用いて、実際に機械学習のタスクを実行する。特に、実際の分類精度を測定することによる、「分類精度の再現の問題」の解決を目標とする。
\section{利用したデータセット}
実験の前提知識として、この節では、実験に使用したデータセットについて記す。機械学習の分野では、分類精度のベンチマークを取るために、様々なデータセットが提供/提案されてきている。同じデータセットに対して、様々な分類モデルやアルゴリズムを用いて分類実験を行うことにより、どの手法が優れているのか比較することが出来る。\par
ここでは、画像認識のデータセットを用いて、深層学習プログラムのベンチマークを行う。画像データを用いる理由は、1つには、画像認識が深層学習が最も高い分類性能を実現している分野だからである。加えて、画像データや画像から抽出された素性は、可視化が比較的容易なことが多い。可視化することで、学習過程を目で見て確かめることが出来るため、アルゴリズムの分析を行いやすい、という利点がある。
\subsection{MNIST}
MNIST database\footnote{http://yann.lecun.com/exdb/mnist/}とは、手書き数字を画像分析によって認識するベンチマークタスクである。このデータセットは、National Institute of Standards and Technology(NIST)が提供する手書き数字のデータにサイズの規格化処理を加え、数字の書き手毎に整理したものである。データはサイズ28x28ピクセルの白黒画像70000件より構成される\cite{lecun1998gradient-based}。それぞれの画像は、0〜9のいずれかの数字1文字に該当している。画像データを認識プログラムに入力して、どの数字に該当するか判別させることで、画像識別の精度を競うことになる。図\ref{c5_mnist_ex}に、MNISTの画像データの一部を示す(\cite{lecun1998gradient-based}より引用した)。\par
MNISTの70000件のデータは、60000件のモデル訓練用データと、10000件の精度測定用データに分かれている。まず60000件のデータを使って識別モデルに学習を行わせた後、未知の10000件のテストデータを実際に識別してみることで、精度を測定する。テストデータを識別している最中に、更なる学習を行うことは許されない。分類器は、過去に学習に使ったデータだけ良く識別できても意味がなく、むしろ未知のデータこそ精度良く分類出来なければならない。モデルが過去のデータに特化してしまうと、かえって未知のデータに対する識別精度が低下することもある。この低下現象は過学習(over fitting)と呼ばれ、機械学習における落とし穴の一つとなっている。MNISTに限らず、機械学習用のデータセットにて、訓練データとテストデータをあらかじめ分けておくことは一般的であり、学習アルゴリズムが過学習を防げているかどうか、判定するために有効な方法の1つとして知られている。\par
\begin{figure}[tbp]
 \begin{center}
  \includegraphics[width=50mm]{img/c5/mnist_ex}
 \end{center}
 \caption{MNISTデータの例}
 \label{c5_mnist_ex}
\end{figure}
MNISTは、様々な画像認識アルゴリズムの作者によって使用されている。MNISTの配布ウェブサイトには、MNISTを利用した論文のリストが、分類誤差によるランキング形式で掲載されている。表\ref{c5_mnist_rank}に、MNISTデータセットにおける各アルゴリズムの分類誤差を、ランキング形式のウェブサイト\footnote{\label{c5_rank}\url{http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html}}より再構成して示す。

% Table generated by Excel2LaTeX from sheet 'c5mnist'
\begin{table}[htbp]
\begin{center}
  %\centering
  \caption{MNISTの分類誤差ランキング}
\input{chap5_mnist_rank}
  \label{c5_mnist_rank}%
  \end{center}
\end{table}%
なお、MNISTのデータによって分類実験をする際、元データを少し歪ませたり、解像度を変更することで入力データの種類を増やすと、良い結果が得られることがわかっている\cite{simard2003best}\cite{lauer2007a-trainable}。一方で、このような元データの変更を禁止した状態で、良い精度を出す試みもある。さらに条件を厳しくして、変形を行わないだけでなく、「2次元の画像データではなく、1次元のベクトルデータである」と考える順序不変(Permutation Invariant, PI)と呼ばれる条件も行われている。このPI条件の場合、2次元的畳み込みネットワークの利用を使うことが出来なくなり、分類精度は大きく落ちることになる。ただ、この条件下でも良い精度を出すことのできるアルゴリズムは、他の1次元のデータ、例えば言語データや音声データにおいても、良い性能を出しやすいと考えられる。今回の実験では、ウェブ工学などへの応用可能性を考えるため、分類モデルが畳み込みレイヤーを含まない場合は、全て順序不変で行っている。畳み込みレイヤーを含むものについては、順序不変にはなっていいが、この場合も元データの変形によるデータ増加は行っていない。

\subsection{CIFAR10}
CIFAR10\footnote{http://www.cs.toronto.edu/~kriz/cifar.html}は、写真を画像分析によって識別するタスクである\cite{krizhevsky2009learning}。入力データは60000件のカラー画像で、どの画像も、飛行機、自動車、鳥、猫、鹿、犬、蛙、馬、船、トラックの10種類のクラスのどれかに属しており、各クラス均等に6000枚ずつの画像が割り振られている。画像データは、GoogleやFlickrなどによるウェブ検索で集められた画像を、人手でラベリングして作られている。また、サイズを32x32ピクセルに縮小されている。\par
MNISTと同じように、60000件のデータは、50000の訓練データと10000件のテストデータに分割されている。まず、分類器にこれらの訓練データを読み取らせて、学習を行わせる。その後、テストデータのうちいくつを正しいクラスに分類することができるのか、分類精度を競うことになる。\par
CIFAR10についても、データの例を\ref{c5_cifar_ex}に、分類誤差のランキングウェブサイト\footnote{\url{http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html}}より、再構成した表を\ref{c5_cifar_rank}に示す。
\begin{figure}[tbp]
 \begin{center}
  \includegraphics[width=100mm]{img/c5/cifar_ex}
 \end{center}
 \caption{CIFAR10データの例}
 \label{c5_cifar_ex}
\end{figure}


\begin{table}[tbp]
 \begin{center}
  \caption{CIFAR10分類誤差のランキング}
 \input{chap5_cifar_rank}
 \end{center}

 \label{c5_cifar_rank}
\end{table}

\section{使用した実装}
この章の実験では、深層学習用の実装として、"Pylearn2"と"Deep Learning Tutorial"という2種類のライブラリによるものを用いた。この2つを選んだのは、どちらも共通してTheanoをベースに書いてあり、自動微分や自動最適化の恩恵を受けられること、ソースコードが非常に系統立てて書いてあり、他のソースコードに比べれば改造が容易なこと、github上にてソースコードが公開されており、利用者が多いことが理由である。それぞれのライブラリの詳細な特徴は、4章にて述べた。\par
ここでは、各ライブラリに含まれている分類モデルの中で、どのモデルを実験に用いたかを記す。

\subsection{Deep Learning Tutorial内のモデル}
Deep Learning Tutorialからは、畳み込みネットワーク(CNN)\footnote{\url{http://deeplearning.net/tutorial/lenet.html}}、積層雑音除去自己符号器(SDA)\footnote{\url{http://deeplearning.net/tutorial/SdA.html}}、深層信念ネットワーク(DBN)\footnote{\url{http://deeplearning.net/tutorial/DBN.html}}の3種類の実装を用いた。加えて、CNNの上から2番目のレイヤーを、Dropout + Rectifier Unitに変更したDReDNet\footnote{\url{http://techtalks.tv/talks/drednets/58115/}}と呼ばれるモデルでも実験した。このときユニットの出力を隠す割合を決める破損率(corruption rate)は、0.5に設定した。

\subsection{Pylearn2内のモデル}
Pylearn2からは、CNN\footnote{\url{http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/convolutional_network.ipynb}}、SDA\footnote{\url{http://nbviewer.ipython.org/github/lisa-lab/pylearn2/blob/master/pylearn2/scripts/tutorials/stacked_autoencoders.ipynb}}、Maxout Network、Maxout+畳み込みレイヤー\footnote{\url{http://deeplearning.net/software/pylearn2/library/models.html#module-pylearn2.models.maxout}}の4種類のモデルを用いた。DBNについては、構成要素であるRBMの実装は用意されているものの、これを組み立ててDBNにする作業はライブラリの利用者に任されている。出来るだけソースを変更せずに用いて分類精度を再現するという、今回の趣旨にそぐわないため、除外した。

\section{使用したマシンとハードウェア性能}
この章の実験では、2種類のサーバマシンを用いている。一方は、深層学習を目的に構成した自作サーバマシンで、GPUを搭載している(physalisと名付ける)。もう一方は、Dell社のPowerEdgeT300\footnote{\url{http://www1.jp.dell.com/jp/ja/premier/servers/pedge_t300/pd.aspx?refid=pedge_t300&cs=jppremier1&s=premier}}という機種のもので、こちらにはGPUは搭載されていない(artemisと名付ける)。表\ref{c5_hardware_spec}に、今回の実験で使用したマシンの主な使用パーツ及び性能を列挙した。また、Pylearn2に実装されているMaxout Networkのソースコードには、実験マシンのパーツ性能を書いたファイルが付属している\footnote{Pylearn2/scripts/papers/maxout/notes}。このファイルの記述内容も、比較のために列挙した。Maxout Networkは、先述したMNISTやCIFAR10のベンチマーク実験において、かなり最先端に高い精度を挙げており、特に順序不変(Permutatin Invariant)のタスクにおいては最も性能が高い。このMaxout Networkの実験に用いられたマシンよりも、ハードウェア面で上回っているならば、ハードウェア面での性能が不足して実験がうまくいかない危険性はかなり低いと言える。今回の実験に使ったマシンで言うと、新しく構成してGPUを搭載したphysalisサーバの方は、論文のマシンよりハードウェア性能的に優れていることがわかる。一方、artemisサーバはGPUを搭載していなかったため、学習速度面にて劣ることが予想される。
\begin{table}[tbp]
 \begin{center}
  \caption{ハードウェア性能の比較}
  \begin{tabular}{|c|c|c|c|c|c|}\hline
  マシン識別名 & GPU & CUDA core & CPU & クロック数 & メモリ容量\\ \hline
physalis & GTX760 & 1152 & Intel CPU Core i7 4770S & 3.1GHz x 8 & 32GB\\ \hline
artemis & (無し) & (無し) & Intel Xeon CPU X3323 & 2.5GHz x 4 & 24GB\\ \hline
(論文) &GTX580 & 512 & Intel Xeon CPU E5620 &  2.4GHz x 4 & (記載無し)\\ \hline
  \end{tabular}
 \end{center}

 \label{c5_hardware_spec}
\end{table}

\section{ベンチマーク実験の詳細}
使用サーバ・ベンチマークセット・ライブラリ・分類モデルの組み合わせについて、分類学習の結果得られる性能を測定した。表\ref{c5_all_result}に結果を示す。ここで、DLTはDeep Learning Tutorial、PL2はPylearn2の略とする。また、PIは、MNISTの実験種類における順序不変タスクのことを指している。この結果に対する考察は、6章にて行う。

% Table generated by Excel2LaTeX from sheet 'summary'
\begin{table}[htbp]
  \centering
  \caption{ベンチマーク実験の結果}
    \begin{tabular}{|c|c|c|c|r|r|r|}\hline
    マシン名 & ライブラリ & データセット & モデル & \shortstack{識別誤差\\(\%)} & \shortstack{実行時間\\(分)} & \shortstack{使用メモリ\\(MB)}\rule[0mm]{0mm}{10mm}\\ \hline
artemis & DLT & CIFAR10 & CNN   & 35.18 & 766   & - \\ \hline
artemis & DLT & CIFAR10 & DBN & 51.01 & 236 &- \\ \hline
artemis & DLT & CIFAR10 & SDA & 56.94 & 1335&- \\ \hline
physalis & DLT & CIFAR10 & CNN & 34.76 & 28&- \\ \hline
physalis & DLT & CIFAR10 & DBN & 50.90& 115 &- \\ \hline
physalis & DLT & CIFAR10 & SDA & 58.64 & 92&- \\ \hline
physalis & DLT & MNIST(PI) & DBN & 1.51& 101 &- \\ \hline
physalis & DLT & MNIST(PI) & SDA & 1.40 & 183 &- \\ \hline
physalis & PL2 & MNIST(PI) & SDA & 1.90 & 128 & 1004 \\ \hline
physalis & PL2 & MNIST(PI) & Maxout & 1.16& 55& 792 \\ \hline
artemis & DLT & MNIST & Drednet & 1.19& 593 &- \\ \hline
physalis & DLT & MNIST & CNN & 0.93& 32&- \\ \hline
physalis & PL2 & MNIST & CNN & 0.68& 30& 796 \\ \hline
physalis & PL2 & MNIST & \shortstack{Maxout\\+畳み込み}\rule[0mm]{0mm}{8mm} & 0.51& 126 & 996 \\ \hline
\end{tabular}%
\label{c5_all_result}%
\end{table}%
\par
\begin{comment}
\subsection{Maxout Networkによる、MNISTの分類タスク(2次元データとして扱う)}
Maxout Networkを分類器として用い、MNISTの分類タスクを行わせた。モデル構造としては、畳み込みレイヤーを2層重ねた上に、全てのニューロンが単純に接続されたMaxout レイヤーを1層付け加え、最後の層にてロジスティック回帰を行って分類結果を出した。
実験を行った結果、分類誤差は0.51\%となった。これは、元の論文が主張している分類誤差より、僅かに悪い結果となった。結果を、表\ref{c5_maxout_mnist2_result}に示す。

\end{comment}

\section{その他に行った実験}
ここでは、上記の組み合わせ実験に当てはまらない、独立して行った実験について記す。

\subsection{Maxout Networkによる、MNIST分類の繰り返し実験}
Maxout Networkを利用して、再現精度Pylearn2を利用するにあたり、何らかの原因でランダム性が発生していないか確かめるため、Pylearn2 + Maxout Networkによる、MNISTの順序不変タスク実験を、10回繰り返して行い、分類性能が変化するどうかを見た。乱数のシードは、元論文の実験が行われたときと同じ値で固定した。つまり、乱数以外の原因でランダム性が発生してしまっていないかどうかをチェックした。これは、実験結果の分類誤差が、Maxout Networkの元の論文よりも僅かではあるが悪くなってしまったため、まずアルゴリズムやハードウェアの動作に含まれるランダム性によって、精度が変化してしまっていないことを確かめるためである。\par
実験の結果、誤差は10回とも共通で、1.16\%となった。なお、平均実行時間は約55分、最大メモリ使用量は793MBだった(表\ref{c5_maxout_mnist1_stat})。\par

\begin{table}[tdp]
\caption{Maxout NetworkによるMNIST(1次元)分類タスク繰り返し実験の詳細}
\begin{center}
\begin{tabular}{|c|c|c|}\hline
 & 平均実行時間(秒) & 平均最大使用メモリ(MB) \\ \hline
事前学習 & 2532.8 & 779.3 \\ \hline
微調整 & 756.7 & 792.5 \\ \hline
全体 & 3289.5 & 792.5 \\ \hline
\end{tabular}
\end{center}
\label{c5_maxout_mnist1_stat}
\end{table}%


\subsection{Maxout Networkによる、CIFAR10の分類タスク}
Maxout+畳み込みのモデルについて、MNISTだけでなく、CIFAR10にも使ってみようと実験を試みた。しかし、この組み合わせの実験を実際に行ったところ、3日間実行を続けたところで、残りエポック数と計算速度の比較より、全体の実行が完了するまでに5日以上かかることが判明した。これはウェブ工学における応用に使う学習アルゴリズムとして、試行錯誤しながら使うものとしては現実的でない実行時間である。また、実験スケジュールの都合もあり、実験の中断を余儀なくされてしまった。%実行が完了した部分までの分類誤差を、図??に示した。[図追加]